{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6680a79a",
   "metadata": {},
   "source": [
    "# Aim\n",
    "Randomly sample points (no optimizer) for 00 ->10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d356f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('C:\\\\Users\\\\Eesh Gupta\\\\Documents\\\\RU Research\\\\Chakram')\n",
    "sys.path.append('C:\\\\Users\\\\Eesh Gupta\\\\Documents\\\\RU Research\\\\Chakram\\\\Double-ECD\\\\May\\\\DECD')\n",
    "\n",
    "import DECD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1295137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DECD import BatchOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)  # supress warnings\n",
    "import h5py\n",
    "\n",
    "# print(\n",
    "#     \"\\nNeed tf version 2.3.0 or later. Using tensorflow version: \"\n",
    "#     + tf.__version__\n",
    "#     + \"\\n\"\n",
    "# )\n",
    "import ECD_control.ECD_optimization.tf_quantum as tfq\n",
    "from ECD_control.ECD_optimization.visualization import VisualizationMixin\n",
    "import qutip as qt\n",
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce9669d",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3485ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The target oscillator state.\n",
    "N1 =10\n",
    "N2 =10\n",
    "Fock1 = 0\n",
    "Fock2= 0\n",
    "psi_i1 = qt.basis(N1,Fock1) #target state\n",
    "psi_i2 = qt.basis(N2,Fock2)\n",
    "psi_initial = qt.tensor(psi_i1, psi_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d606f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The target oscillator state.\n",
    "N1 =10\n",
    "N2 =10\n",
    "Fock1 = 1\n",
    "Fock2= 0\n",
    "psi_t1 = qt.basis(N1,Fock1) #target state\n",
    "psi_t2 = qt.basis(N2,Fock2)\n",
    "psi_target = qt.tensor(psi_t1, psi_t2)\n",
    "psi_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization of ECD Circuit parameters (betas, phis, and thetas)\n",
    "#the optimization options\n",
    "opt_params = {\n",
    "'N_blocks' : 5, #circuit depth\n",
    "'N_multistart' : 2, #Batch size (number of circuit optimizations to run in parallel)\n",
    "'epochs' : 1, #number of epochs before termination\n",
    "'epoch_size' : 20, #number of adam steps per epoch\n",
    "'learning_rate' : 0.01, #adam learning rate\n",
    "'term_fid' : 0.995, #terminal fidelitiy\n",
    "'dfid_stop' : 1e-6, #stop if dfid between two epochs is smaller than this number\n",
    "'beta_scale' : 3.0, #maximum |beta| for random initialization\n",
    "'gamma_scale' : 3.0, #maximum |gamma| for random initialization\n",
    "'N_cav1': N1, #number of levels in mode 1\n",
    "'N_cav2': N2, #number of levels in mode 2\n",
    "'initial_states' : [qt.tensor(qt.basis(2,0),psi_initial)], #qubit tensor oscillator, start in |g> |0>\n",
    "'target_states' : [qt.tensor(qt.basis(2,0), psi_target)], #end in |e> |target>.\n",
    "'name' : 'Fock1 %d' % Fock1, #name for printing and saving\n",
    "'filename' : None, #if no filename specified, results will be saved in this folder under 'name.h5'\n",
    "}\n",
    "\n",
    "\n",
    "#note: optimizer includes pi pulse in every ECD step. However, final ECD step is implemented \n",
    "#in experiment as a displacement since the qubit and oscillator should be disentangled at this point.\n",
    "#So, we ask the optimizer to end in |e> |target> instead of |g>|target>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e704277",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create optimization object. \n",
    "#initial params will be randomized upon creation\n",
    "opt = BatchOptimizer(**opt_params)\n",
    "\n",
    "#print optimization info. \n",
    "opt.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554f175",
   "metadata": {},
   "source": [
    "# Randomly sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a1b1b",
   "metadata": {},
   "source": [
    "### First we create a blackbox which given a set of ECD parameters, finds the fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afcf2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackbox(param_array):\n",
    "    '''\n",
    "    Input: array of params\n",
    "    Output: fidelity\n",
    "    '''\n",
    "    \n",
    "    #since 2 multistarts is minimum in batch optimizer, we create 2 copies of everything\n",
    "    params_array_double = double_array(param_array)\n",
    "    #betas_rho, betas_angle, gammas_rho, gammas_angle, alphas1_rho, alphas1_angle, alphas2_rho, alphas2_angle, phis, etas, thetas = params_array_double\n",
    "    \n",
    "    #convert from numpy array to tensor\n",
    "    params_tensor = convert_to_tensor(params_array_double)\n",
    "    betas_rho, betas_angle, gammas_rho, gammas_angle, alphas1_rho, alphas1_angle, alphas2_rho, alphas2_angle, phis, etas, thetas = params_tensor\n",
    "    \n",
    "    #compute fidelity\n",
    "    fids_tensor =opt.batch_fidelities(\n",
    "        betas_rho,\n",
    "        betas_angle,\n",
    "        gammas_rho,\n",
    "        gammas_angle,\n",
    "        alphas1_rho,\n",
    "        alphas1_angle,\n",
    "        alphas2_rho,\n",
    "        alphas2_angle,\n",
    "        phis,\n",
    "        etas,\n",
    "        thetas\n",
    "        ) \n",
    "    fid = fids_tensor[0]\n",
    "    return float(fid.numpy())\n",
    "\n",
    "def double_array(arry): \n",
    "    '''\n",
    "    Reason: Batch optimzier cannot work with 1 multistart, so gotta work with 2\n",
    "    \n",
    "    Input: given an array [[a,b], [c]]\n",
    "    Output: [[[a,a], [b,b]], [[c,c]]]\n",
    "    '''\n",
    "    new_arry = []\n",
    "    for arr in arry:\n",
    "        new_arr = []\n",
    "        for num in arr: \n",
    "            new_arr.append([num,num])\n",
    "        new_arry.append(new_arr)\n",
    "    return new_arry\n",
    "\n",
    "def convert_to_tensor(args):\n",
    "    '''\n",
    "    Input: list of numpy arrays\n",
    "    Output: tensor objects\n",
    "    '''\n",
    "    tensors =[]\n",
    "    for arg in args:\n",
    "        t = tf.convert_to_tensor(np.array(arg), dtype = tf.float32)\n",
    "        #print(t.shape)\n",
    "        tensors.append(t)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import random\n",
    "import math\n",
    "#randomly sample parameters\n",
    "def random_radius():\n",
    "    return random.uniform(-3, 3)\n",
    "def random_angle():\n",
    "    return random.uniform(-math.pi, math.pi)\n",
    "\n",
    "def generate_random_params(n_layers):\n",
    "    '''\n",
    "    Output: array of subarrays where each subarray is some parameter\n",
    "    '''\n",
    "    betas_rho =[ random_radius() for i in range(n_layers)]\n",
    "    betas_angle = [random_angle() for i in range(n_layers)]\n",
    "    gammas_rho = [random_radius() for i in range(n_layers)]\n",
    "    gammas_angle = [random_angle() for i in range(n_layers)]\n",
    "    alphas1_rho = [0.0]\n",
    "    alphas1_angle = [0.0]\n",
    "    alphas2_rho = [0.0]\n",
    "    alphas2_angle = [0.0]\n",
    "    phis = [random_angle() for i in range(n_layers)]\n",
    "    etas= [math.pi/2 for i in range(n_layers)]\n",
    "    thetas = [random_angle() for i in range(n_layers)]\n",
    "    \n",
    "    params = [betas_rho,\n",
    "        betas_angle,\n",
    "        gammas_rho,\n",
    "        gammas_angle,\n",
    "        alphas1_rho,\n",
    "        alphas1_angle,\n",
    "        alphas2_rho,\n",
    "        alphas2_angle,\n",
    "        phis,\n",
    "        etas,\n",
    "        thetas]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox(generate_random_params(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fids = []\n",
    "params = []\n",
    "iters = []\n",
    "\n",
    "for i in range(1000):\n",
    "    param = generate_random_params(5)\n",
    "    fid = blackbox(param)\n",
    "    params.append(param)\n",
    "    fids.append(fid)\n",
    "    iters.append(i)\n",
    "    plt.plot(iters, fids,marker = 'o' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd4c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
